
docker build -t ravaen_payload .

# auto run
docker run -it --rm -v /dev:/dev \
                -v "/$(pwd)/weights":/weights \
                -v "/$(pwd)/unibap_dataset":/unibap_dataset \
                -v "/$(pwd)/results":/results \
                -m 2g ravaen_payload

# add to the end of the command if you want to interact with the code inside, starting a bash
bash
python3.7 run_inference.py

python3.7 run_inference.py --batch_size 2 --selected_images first_30
python3.7 run_inference.py --batch_size 4 --selected_images first_30
python3.7 run_inference.py --batch_size 8 --selected_images first_30
python3.7 run_inference.py --batch_size 16 --selected_images first_30
python3.7 run_inference.py --batch_size 32 --selected_images first_30
python3.7 run_inference.py --batch_size 64 --selected_images first_30
python3.7 run_inference.py --batch_size 128 --selected_images first_30

cd ../tile_classifier
python3.7 run_train.py

python3.7 run_train.py --batch_size 2
python3.7 run_train.py --batch_size 4
python3.7 run_train.py --batch_size 8
python3.7 run_train.py --batch_size 16
python3.7 run_train.py --batch_size 32
python3.7 run_train.py --batch_size 64
python3.7 run_train.py --batch_size 128
python3.7 run_train.py --batch_size 256


docker run -it --rm -v /dev:/dev -m 2g ravaen_payload


### Run on the whole dataset:
docker run -it --rm -v /dev:/dev \
                -v "/$(pwd)/weights":/weights \
                -v "PATH_TO_FULL_DATASET":/unibap_dataset_small \
                -v "/$(pwd)/results":/results \
                -m 2g ravaen_payload


### On small subset:

python3.7 ravaen_payload/run_inference.py --batch_size 64 --selected_images first_30 --unibap_dataset_filter none

python3.7 ravaen_payload/run_inference.py --batch_size 64 --selected_images first_30 --unibap_dataset_filter none --special_save_logvars True
